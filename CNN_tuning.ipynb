{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef5622e-8382-43fa-a28e-962c0216dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f289253-d55d-49e4-a928-362efd649d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('cxr-record-list.csv')\n",
    "df4 = pd.read_csv('mimic-cxr-2.0.0-chexpert.csv')\n",
    "df6 = pd.read_csv('mimic-cxr-2.0.0-metadata.csv')\n",
    "merge_df = df2.merge(df4,on=['subject_id','study_id'],how='inner')\n",
    "merge_df = merge_df.merge(df6[['dicom_id', 'ViewPosition']],on='dicom_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9e2c41-f0b7-41a4-8646-7f1f1429c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_train_val(df,img_path,disease):\n",
    "    '''\n",
    "    split data to train ans validation\n",
    "    disease labe must be 1 for case or 0 for control, labeled by chexpert\n",
    "    images are all posterior to anterior (filtered when downloading)\n",
    "    choose one PA image per subject\n",
    "    '''\n",
    "    file_ids = [file.replace(\".jpg\",\"\") for file in os.listdir(img_path)]\n",
    "    df = df[df['dicom_id'].isin(file_ids)]\n",
    "    \n",
    "    df.loc[:,'image_path'] = img_path+ '/' + df['dicom_id'] + '.jpg'\n",
    "    \n",
    "    input_df = df[df[disease].isin([0,1])].drop_duplicates('subject_id')\n",
    "    train_df, val_df = train_test_split(\n",
    "        input_df, \n",
    "        test_size=0.2, \n",
    "        random_state=1, \n",
    "        stratify=input_df[disease]\n",
    "    )\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fefc441-ab0c-4153-9cf7-3a872bf45190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the custom dataset class\n",
    "class disease_Dataset(Dataset):\n",
    "    def __init__(self, df, disease, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.disease = disease\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert(\"RGB\") #images are gray scale, but models require RGB\n",
    "        label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def generate_dataLoader(disease, train_df,val_df):\n",
    "    # DataLoaders\n",
    "    train_dataset = disease_Dataset(train_df,disease, transform)\n",
    "    val_dataset = disease_Dataset(val_df,disease, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896aa03a-0ce5-4a86-96ac-0390d8e4b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, lr, weight_decay):\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    num_epochs = 10\n",
    "    patience = 3  # Number of epochs to wait for improvement\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "        val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "        val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"  Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0  # Reset counter if validation loss improves\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe789b4-9ee3-40f7-afb0-d48583455d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = csv_to_train_val(merge_df,'images_NEW','Pneumonia') #2700\n",
    "train_loader, val_loader = generate_dataLoader('Pneumonia',train_df,val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fc2466a-acdb-4fcc-8ccf-2abface6ec25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.9771\n",
      "  Validation Loss: 0.8893\n",
      "  Validation Accuracy: 0.3025\n",
      "  Validation F1 Score: 0.4378\n",
      "  Validation AUC: 0.5210\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.8454\n",
      "  Validation Loss: 0.8999\n",
      "  Validation Accuracy: 0.3086\n",
      "  Validation F1 Score: 0.4343\n",
      "  Validation AUC: 0.5570\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.7504\n",
      "  Validation Loss: 0.8781\n",
      "  Validation Accuracy: 0.3457\n",
      "  Validation F1 Score: 0.4536\n",
      "  Validation AUC: 0.5857\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.6630\n",
      "  Validation Loss: 0.8257\n",
      "  Validation Accuracy: 0.4074\n",
      "  Validation F1 Score: 0.4419\n",
      "  Validation AUC: 0.5614\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.5783\n",
      "  Validation Loss: 0.8266\n",
      "  Validation Accuracy: 0.4321\n",
      "  Validation F1 Score: 0.4321\n",
      "  Validation AUC: 0.5437\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.5061\n",
      "  Validation Loss: 0.7849\n",
      "  Validation Accuracy: 0.4691\n",
      "  Validation F1 Score: 0.3768\n",
      "  Validation AUC: 0.5416\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.4278\n",
      "  Validation Loss: 0.8137\n",
      "  Validation Accuracy: 0.4444\n",
      "  Validation F1 Score: 0.3662\n",
      "  Validation AUC: 0.5376\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.3636\n",
      "  Validation Loss: 0.7763\n",
      "  Validation Accuracy: 0.5247\n",
      "  Validation F1 Score: 0.3740\n",
      "  Validation AUC: 0.5381\n",
      "Epoch 9/20:\n",
      "  Training Loss: 0.2973\n",
      "  Validation Loss: 0.7981\n",
      "  Validation Accuracy: 0.5247\n",
      "  Validation F1 Score: 0.3740\n",
      "  Validation AUC: 0.5383\n",
      "Epoch 10/20:\n",
      "  Training Loss: 0.2500\n",
      "  Validation Loss: 0.7652\n",
      "  Validation Accuracy: 0.5679\n",
      "  Validation F1 Score: 0.3636\n",
      "  Validation AUC: 0.5399\n",
      "Epoch 11/20:\n",
      "  Training Loss: 0.1939\n",
      "  Validation Loss: 0.7756\n",
      "  Validation Accuracy: 0.5802\n",
      "  Validation F1 Score: 0.3585\n",
      "  Validation AUC: 0.5435\n",
      "Epoch 12/20:\n",
      "  Training Loss: 0.1621\n",
      "  Validation Loss: 0.8081\n",
      "  Validation Accuracy: 0.5802\n",
      "  Validation F1 Score: 0.3818\n",
      "  Validation AUC: 0.5447\n",
      "Epoch 13/20:\n",
      "  Training Loss: 0.1242\n",
      "  Validation Loss: 0.7810\n",
      "  Validation Accuracy: 0.6049\n",
      "  Validation F1 Score: 0.3600\n",
      "  Validation AUC: 0.5582\n",
      "Epoch 14/20:\n",
      "  Training Loss: 0.1062\n",
      "  Validation Loss: 0.7861\n",
      "  Validation Accuracy: 0.6358\n",
      "  Validation F1 Score: 0.3789\n",
      "  Validation AUC: 0.5570\n",
      "Epoch 15/20:\n",
      "  Training Loss: 0.0793\n",
      "  Validation Loss: 0.7896\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3830\n",
      "  Validation AUC: 0.5572\n",
      "Epoch 16/20:\n",
      "  Training Loss: 0.0672\n",
      "  Validation Loss: 0.7821\n",
      "  Validation Accuracy: 0.6543\n",
      "  Validation F1 Score: 0.3913\n",
      "  Validation AUC: 0.5559\n",
      "Epoch 17/20:\n",
      "  Training Loss: 0.0580\n",
      "  Validation Loss: 0.8070\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3696\n",
      "  Validation AUC: 0.5661\n",
      "Epoch 18/20:\n",
      "  Training Loss: 0.0569\n",
      "  Validation Loss: 0.8455\n",
      "  Validation Accuracy: 0.6358\n",
      "  Validation F1 Score: 0.3918\n",
      "  Validation AUC: 0.5686\n",
      "Epoch 19/20:\n",
      "  Training Loss: 0.0468\n",
      "  Validation Loss: 0.8148\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3830\n",
      "  Validation AUC: 0.5676\n",
      "Epoch 20/20:\n",
      "  Training Loss: 0.0603\n",
      "  Validation Loss: 0.8120\n",
      "  Validation Accuracy: 0.6543\n",
      "  Validation F1 Score: 0.3636\n",
      "  Validation AUC: 0.5680\n",
      "CPU times: user 59min 28s, sys: 25.1 s, total: 59min 53s\n",
      "Wall time: 1h 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4700 1 & all 0\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a7ecf4-21de-4f26-af50-3f608260ba96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.6381\n",
      "  Validation Loss: 0.6231\n",
      "  Validation Accuracy: 0.6916\n",
      "  Validation F1 Score: 0.2353\n",
      "  Validation AUC: 0.6292\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.5734\n",
      "  Validation Loss: 0.5982\n",
      "  Validation Accuracy: 0.6843\n",
      "  Validation F1 Score: 0.0942\n",
      "  Validation AUC: 0.6561\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.5273\n",
      "  Validation Loss: 0.5896\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.1224\n",
      "  Validation AUC: 0.6706\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.4814\n",
      "  Validation Loss: 0.5820\n",
      "  Validation Accuracy: 0.6788\n",
      "  Validation F1 Score: 0.1776\n",
      "  Validation AUC: 0.6843\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.4316\n",
      "  Validation Loss: 0.5822\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.2110\n",
      "  Validation AUC: 0.6785\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.3786\n",
      "  Validation Loss: 0.5786\n",
      "  Validation Accuracy: 0.6898\n",
      "  Validation F1 Score: 0.3254\n",
      "  Validation AUC: 0.6876\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.3127\n",
      "  Validation Loss: 0.5928\n",
      "  Validation Accuracy: 0.6953\n",
      "  Validation F1 Score: 0.3128\n",
      "  Validation AUC: 0.6697\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.2475\n",
      "  Validation Loss: 0.6080\n",
      "  Validation Accuracy: 0.6880\n",
      "  Validation F1 Score: 0.3498\n",
      "  Validation AUC: 0.6576\n",
      "Epoch 9/20:\n",
      "  Training Loss: 0.1798\n",
      "  Validation Loss: 0.6366\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.3813\n",
      "  Validation AUC: 0.6488\n",
      "Epoch 10/20:\n",
      "  Training Loss: 0.1301\n",
      "  Validation Loss: 0.6653\n",
      "  Validation Accuracy: 0.6606\n",
      "  Validation F1 Score: 0.4076\n",
      "  Validation AUC: 0.6390\n",
      "Epoch 11/20:\n",
      "  Training Loss: 0.0902\n",
      "  Validation Loss: 0.7034\n",
      "  Validation Accuracy: 0.6770\n",
      "  Validation F1 Score: 0.3610\n",
      "  Validation AUC: 0.6377\n",
      "Epoch 12/20:\n",
      "  Training Loss: 0.0658\n",
      "  Validation Loss: 0.7323\n",
      "  Validation Accuracy: 0.6478\n",
      "  Validation F1 Score: 0.4134\n",
      "  Validation AUC: 0.6280\n",
      "Epoch 13/20:\n",
      "  Training Loss: 0.0503\n",
      "  Validation Loss: 0.7479\n",
      "  Validation Accuracy: 0.6624\n",
      "  Validation F1 Score: 0.3771\n",
      "  Validation AUC: 0.6351\n",
      "Epoch 14/20:\n",
      "  Training Loss: 0.0380\n",
      "  Validation Loss: 0.7797\n",
      "  Validation Accuracy: 0.6752\n",
      "  Validation F1 Score: 0.3946\n",
      "  Validation AUC: 0.6289\n",
      "Epoch 15/20:\n",
      "  Training Loss: 0.0321\n",
      "  Validation Loss: 0.8122\n",
      "  Validation Accuracy: 0.6423\n",
      "  Validation F1 Score: 0.4432\n",
      "  Validation AUC: 0.6235\n",
      "Epoch 16/20:\n",
      "  Training Loss: 0.0284\n",
      "  Validation Loss: 0.8237\n",
      "  Validation Accuracy: 0.6405\n",
      "  Validation F1 Score: 0.4223\n",
      "  Validation AUC: 0.6351\n",
      "Epoch 17/20:\n",
      "  Training Loss: 0.0246\n",
      "  Validation Loss: 0.8643\n",
      "  Validation Accuracy: 0.6551\n",
      "  Validation F1 Score: 0.3762\n",
      "  Validation AUC: 0.6162\n",
      "Epoch 18/20:\n",
      "  Training Loss: 0.0191\n",
      "  Validation Loss: 0.8738\n",
      "  Validation Accuracy: 0.6533\n",
      "  Validation F1 Score: 0.3791\n",
      "  Validation AUC: 0.6195\n",
      "Epoch 19/20:\n",
      "  Training Loss: 0.0169\n",
      "  Validation Loss: 0.8942\n",
      "  Validation Accuracy: 0.6569\n",
      "  Validation F1 Score: 0.4051\n",
      "  Validation AUC: 0.6157\n",
      "Epoch 20/20:\n",
      "  Training Loss: 0.0148\n",
      "  Validation Loss: 0.9292\n",
      "  Validation Accuracy: 0.6697\n",
      "  Validation F1 Score: 0.3604\n",
      "  Validation AUC: 0.6138\n",
      "CPU times: user 1h 32min 16s, sys: 46.9 s, total: 1h 33min 3s\n",
      "Wall time: 1h 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cfcd8bb-f0e1-486b-b345-0663575cd01c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6382\n",
      "  Validation Loss: 0.5733\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.0278\n",
      "  Validation AUC: 0.7130\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.2959\n",
      "  Validation Loss: 0.6541\n",
      "  Validation Accuracy: 0.7309\n",
      "  Validation F1 Score: 0.2683\n",
      "  Validation AUC: 0.7170\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.0847\n",
      "  Validation Loss: 0.5407\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5045\n",
      "  Validation AUC: 0.7738\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0230\n",
      "  Validation Loss: 0.6324\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5133\n",
      "  Validation AUC: 0.7545\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.0078\n",
      "  Validation Loss: 0.6623\n",
      "  Validation Accuracy: 0.7489\n",
      "  Validation F1 Score: 0.4717\n",
      "  Validation AUC: 0.7755\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.0059\n",
      "  Validation Loss: 0.6439\n",
      "  Validation Accuracy: 0.7623\n",
      "  Validation F1 Score: 0.5310\n",
      "  Validation AUC: 0.7810\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.0041\n",
      "  Validation Loss: 0.6519\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5133\n",
      "  Validation AUC: 0.7808\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.0028\n",
      "  Validation Loss: 0.6748\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.4860\n",
      "  Validation AUC: 0.7816\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.0018\n",
      "  Validation Loss: 0.7044\n",
      "  Validation Accuracy: 0.7578\n",
      "  Validation F1 Score: 0.4906\n",
      "  Validation AUC: 0.7796\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.0020\n",
      "  Validation Loss: 0.6936\n",
      "  Validation Accuracy: 0.7623\n",
      "  Validation F1 Score: 0.5225\n",
      "  Validation AUC: 0.7840\n",
      "CPU times: user 18min 9s, sys: 19.6 s, total: 18min 28s\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Define ResNet model\n",
    "model_resnet = models.resnet18(pretrained=True)\n",
    "model_resnet.fc = torch.nn.Linear(model_resnet.fc.in_features, 1)\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_resnet(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    model_resnet.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_resnet(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(val_dataset)\n",
    "\n",
    "    # Validation metrics\n",
    "    val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "    val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "    val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"  Validation AUC: {val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f252e-75dc-4514-b43d-eaa8f54bdc4b",
   "metadata": {},
   "source": [
    "## hyper parameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e9dab10-b361-487a-b9c3-9f6ec9891aaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=0.001, Batch Size=32, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with AUC=0.6037\n",
      "New best model with AUC=0.6600\n",
      "New best model with AUC=0.6921\n",
      "New best model with AUC=0.7130\n",
      "\n",
      "Testing: LR=0.001, Batch Size=32, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with AUC=0.7140\n",
      "New best model with AUC=0.7393\n",
      "\n",
      "Testing: LR=0.001, Batch Size=64, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=0.001, Batch Size=64, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=0.0001, Batch Size=32, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=0.0001, Batch Size=32, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with AUC=0.7422\n",
      "New best model with AUC=0.7482\n",
      "New best model with AUC=0.7491\n",
      "New best model with AUC=0.7553\n",
      "\n",
      "Testing: LR=0.0001, Batch Size=64, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=0.0001, Batch Size=64, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=1e-05, Batch Size=32, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=1e-05, Batch Size=32, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model with AUC=0.7790\n",
      "New best model with AUC=0.7880\n",
      "New best model with AUC=0.7928\n",
      "\n",
      "Testing: LR=1e-05, Batch Size=64, Weight Decay=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: LR=1e-05, Batch Size=64, Weight Decay=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'lr': 1e-05, 'batch_size': 32, 'weight_decay': 0.0001}, Best Validation AUC: 0.7928\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid\n",
    "num_epochs = 10 \n",
    "hyperparams = {\n",
    "    'learning_rates': [1e-3, 1e-4, 1e-5],\n",
    "    'batch_sizes': [32, 64],\n",
    "    'weight_decays': [0, 1e-4],\n",
    "}\n",
    "\n",
    "best_hyperparams = None\n",
    "best_val_auc = 0.0\n",
    "\n",
    "for lr in hyperparams['learning_rates']:\n",
    "    for batch_size in hyperparams['batch_sizes']:\n",
    "        for weight_decay in hyperparams['weight_decays']:\n",
    "            print(f\"\\nTesting: LR={lr}, Batch Size={batch_size}, Weight Decay={weight_decay}\")\n",
    "            \n",
    "            # Reinitialize model, optimizer, and dataloaders\n",
    "            model_resnet = models.resnet18(pretrained=True)\n",
    "            model_resnet.fc = torch.nn.Linear(model_resnet.fc.in_features, 1)\n",
    "            model_resnet = model_resnet.to(device)\n",
    "            criterion = torch.nn.BCEWithLogitsLoss()\n",
    "            optimizer = torch.optim.Adam(model_resnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            # Training loop (simplified for one epoch)\n",
    "            for epoch in range(num_epochs):\n",
    "                model_resnet.train()\n",
    "                for images, labels in train_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model_resnet(images).squeeze()\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Validation evaluation\n",
    "                model_resnet.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in val_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = model_resnet(images).squeeze()\n",
    "                        val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "                        val_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "                # Track the best configuration\n",
    "                if val_auc > best_val_auc:\n",
    "                    best_val_auc = val_auc\n",
    "                    best_hyperparams = {'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay}\n",
    "                    \n",
    "                    \n",
    "                    print(f\"New best model with AUC={val_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: {best_hyperparams}, Best Validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d71dde6-9dc5-4fe4-ad89-fcdcadd66a09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.001, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6479\n",
      "  Validation Loss: 0.5885\n",
      "  Validation Accuracy: 0.6837\n",
      "  Validation F1 Score: 0.4335\n",
      "  Validation AUC: 0.6721\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5862\n",
      "  Validation Loss: 0.6640\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.0654\n",
      "  Validation AUC: 0.6549\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5766\n",
      "  Validation Loss: 0.6036\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3470\n",
      "  Validation AUC: 0.6305\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5580\n",
      "  Validation Loss: 0.6936\n",
      "  Validation Accuracy: 0.6263\n",
      "  Validation F1 Score: 0.4172\n",
      "  Validation AUC: 0.6166\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.001, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6562\n",
      "  Validation Loss: 0.6730\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.6546\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5940\n",
      "  Validation Loss: 0.5925\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.0270\n",
      "  Validation AUC: 0.6361\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5759\n",
      "  Validation Loss: 0.6244\n",
      "  Validation Accuracy: 0.6794\n",
      "  Validation F1 Score: 0.2775\n",
      "  Validation AUC: 0.6198\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5564\n",
      "  Validation Loss: 0.6064\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.1006\n",
      "  Validation AUC: 0.6587\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5300\n",
      "  Validation Loss: 0.6357\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.1538\n",
      "  Validation AUC: 0.6659\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.0001, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6217\n",
      "  Validation Loss: 0.5791\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.2932\n",
      "  Validation AUC: 0.6840\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.3187\n",
      "  Validation Loss: 0.6597\n",
      "  Validation Accuracy: 0.6773\n",
      "  Validation F1 Score: 0.4062\n",
      "  Validation AUC: 0.6484\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.0957\n",
      "  Validation Loss: 0.7291\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.4146\n",
      "  Validation AUC: 0.6884\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0306\n",
      "  Validation Loss: 0.8418\n",
      "  Validation Accuracy: 0.6582\n",
      "  Validation F1 Score: 0.4059\n",
      "  Validation AUC: 0.6563\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.0001, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6116\n",
      "  Validation Loss: 0.5780\n",
      "  Validation Accuracy: 0.6858\n",
      "  Validation F1 Score: 0.3934\n",
      "  Validation AUC: 0.6989\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.3569\n",
      "  Validation Loss: 0.8998\n",
      "  Validation Accuracy: 0.5605\n",
      "  Validation F1 Score: 0.4733\n",
      "  Validation AUC: 0.6241\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.1057\n",
      "  Validation Loss: 0.8787\n",
      "  Validation Accuracy: 0.6242\n",
      "  Validation F1 Score: 0.3218\n",
      "  Validation AUC: 0.6184\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0371\n",
      "  Validation Loss: 0.9318\n",
      "  Validation Accuracy: 0.6561\n",
      "  Validation F1 Score: 0.4214\n",
      "  Validation AUC: 0.6525\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6331\n",
      "  Validation Loss: 0.6678\n",
      "  Validation Accuracy: 0.5732\n",
      "  Validation F1 Score: 0.3964\n",
      "  Validation AUC: 0.5753\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5443\n",
      "  Validation Loss: 0.5810\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.2474\n",
      "  Validation AUC: 0.6737\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.4797\n",
      "  Validation Loss: 0.5750\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.3514\n",
      "  Validation AUC: 0.6871\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4165\n",
      "  Validation Loss: 0.5719\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3529\n",
      "  Validation AUC: 0.6894\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.3515\n",
      "  Validation Loss: 0.5710\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.4034\n",
      "  Validation AUC: 0.6972\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.2837\n",
      "  Validation Loss: 0.5739\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3966\n",
      "  Validation AUC: 0.6991\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2222\n",
      "  Validation Loss: 0.5829\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.4132\n",
      "  Validation AUC: 0.6998\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.1614\n",
      "  Validation Loss: 0.6026\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.4257\n",
      "  Validation AUC: 0.6918\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6431\n",
      "  Validation Loss: 0.6199\n",
      "  Validation Accuracy: 0.6794\n",
      "  Validation F1 Score: 0.2775\n",
      "  Validation AUC: 0.6321\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5512\n",
      "  Validation Loss: 0.5753\n",
      "  Validation Accuracy: 0.7325\n",
      "  Validation F1 Score: 0.3762\n",
      "  Validation AUC: 0.6915\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.4813\n",
      "  Validation Loss: 0.5634\n",
      "  Validation Accuracy: 0.7282\n",
      "  Validation F1 Score: 0.3786\n",
      "  Validation AUC: 0.7056\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4186\n",
      "  Validation Loss: 0.5555\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3889\n",
      "  Validation AUC: 0.7154\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.3514\n",
      "  Validation Loss: 0.5537\n",
      "  Validation Accuracy: 0.7346\n",
      "  Validation F1 Score: 0.4541\n",
      "  Validation AUC: 0.7179\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.2820\n",
      "  Validation Loss: 0.5543\n",
      "  Validation Accuracy: 0.7346\n",
      "  Validation F1 Score: 0.4541\n",
      "  Validation AUC: 0.7172\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2240\n",
      "  Validation Loss: 0.5661\n",
      "  Validation Accuracy: 0.7261\n",
      "  Validation F1 Score: 0.4416\n",
      "  Validation AUC: 0.7094\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.1629\n",
      "  Validation Loss: 0.5739\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.4585\n",
      "  Validation AUC: 0.7092\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "# try learning rate and weight dacay\n",
    "\n",
    "for lr in [1e-3, 1e-4, 1e-5]:\n",
    "    for weight_decay in [0, 1e-4]:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "        model = model.to(device)\n",
    "        print(f\"=====lr: {lr}, decay: {weight_decay}=====\")\n",
    "        train(model, train_loader, val_loader, lr, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205f8efc-09af-4c3f-b1dd-e92a5921d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, lr=1e-5, weight_decay=1e-4, dropout_prob=0.5, use_scheduler=True, augmentations=None):\n",
    "\n",
    "    # Apply augmentations if provided\n",
    "    if augmentations:\n",
    "        train_loader.dataset.transform = augmentations\n",
    "\n",
    "    # Add dropout to the fully connected layer dynamically\n",
    "    model.fc = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=dropout_prob),\n",
    "        torch.nn.Linear(model.fc.in_features, 1)\n",
    "    ).to(device)  # Ensure the modified layer is on the correct device\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Optionally use a learning rate scheduler\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.1, patience=2, verbose=True\n",
    "        )\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    num_epochs = 10\n",
    "    patience = 3  # Number of epochs to wait for improvement\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # Move images and labels to the specified device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                # Move images and labels to the specified device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()  # Move predictions to CPU for evaluation\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())  # Move labels to CPU for evaluation\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "        val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "        val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"  Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Update the learning rate scheduler\n",
    "        if use_scheduler:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0  # Reset counter if validation loss improves\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b980234-ece1-4a52-ac6c-8d98bc7f6e95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: True, augmentations: True=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6602\n",
      "  Validation Loss: 0.6042\n",
      "  Validation Accuracy: 0.6858\n",
      "  Validation F1 Score: 0.0864\n",
      "  Validation AUC: 0.6128\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5814\n",
      "  Validation Loss: 0.5913\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.3408\n",
      "  Validation AUC: 0.6699\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5214\n",
      "  Validation Loss: 0.5816\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.3498\n",
      "  Validation AUC: 0.6796\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4651\n",
      "  Validation Loss: 0.5717\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3839\n",
      "  Validation AUC: 0.6937\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4134\n",
      "  Validation Loss: 0.5701\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3805\n",
      "  Validation AUC: 0.6957\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.3533\n",
      "  Validation Loss: 0.5745\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.3739\n",
      "  Validation AUC: 0.6950\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3006\n",
      "  Validation Loss: 0.5758\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.4418\n",
      "  Validation AUC: 0.7012\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.2361\n",
      "  Validation Loss: 0.5874\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.4688\n",
      "  Validation AUC: 0.6990\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7568\n",
      "  Validation Loss: 0.7303\n",
      "  Validation Accuracy: 0.4671\n",
      "  Validation F1 Score: 0.4803\n",
      "  Validation AUC: 0.6101\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6377\n",
      "  Validation Loss: 0.6509\n",
      "  Validation Accuracy: 0.6093\n",
      "  Validation F1 Score: 0.4945\n",
      "  Validation AUC: 0.6465\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5570\n",
      "  Validation Loss: 0.6144\n",
      "  Validation Accuracy: 0.6688\n",
      "  Validation F1 Score: 0.4429\n",
      "  Validation AUC: 0.6649\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4867\n",
      "  Validation Loss: 0.6015\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.4535\n",
      "  Validation AUC: 0.6695\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4216\n",
      "  Validation Loss: 0.5849\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.4498\n",
      "  Validation AUC: 0.6810\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.3636\n",
      "  Validation Loss: 0.5917\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.4689\n",
      "  Validation AUC: 0.6837\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2949\n",
      "  Validation Loss: 0.5837\n",
      "  Validation Accuracy: 0.7261\n",
      "  Validation F1 Score: 0.4735\n",
      "  Validation AUC: 0.6814\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.2342\n",
      "  Validation Loss: 0.5967\n",
      "  Validation Accuracy: 0.7240\n",
      "  Validation F1 Score: 0.4758\n",
      "  Validation AUC: 0.6814\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.1762\n",
      "  Validation Loss: 0.6243\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.4794\n",
      "  Validation AUC: 0.6755\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.1363\n",
      "  Validation Loss: 0.6586\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.4983\n",
      "  Validation AUC: 0.6760\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6791\n",
      "  Validation Loss: 0.6387\n",
      "  Validation Accuracy: 0.6454\n",
      "  Validation F1 Score: 0.2304\n",
      "  Validation AUC: 0.5650\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6329\n",
      "  Validation Loss: 0.6015\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3349\n",
      "  Validation AUC: 0.6514\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6034\n",
      "  Validation Loss: 0.5901\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3704\n",
      "  Validation AUC: 0.6688\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5981\n",
      "  Validation Loss: 0.5778\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3491\n",
      "  Validation AUC: 0.6870\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5770\n",
      "  Validation Loss: 0.5691\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.3147\n",
      "  Validation AUC: 0.6949\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.5714\n",
      "  Validation Loss: 0.5660\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3512\n",
      "  Validation AUC: 0.6973\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5516\n",
      "  Validation Loss: 0.5649\n",
      "  Validation Accuracy: 0.7219\n",
      "  Validation F1 Score: 0.3732\n",
      "  Validation AUC: 0.6977\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5461\n",
      "  Validation Loss: 0.5638\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3592\n",
      "  Validation AUC: 0.7016\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5328\n",
      "  Validation Loss: 0.5611\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4093\n",
      "  Validation AUC: 0.7038\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5087\n",
      "  Validation Loss: 0.5624\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3575\n",
      "  Validation AUC: 0.7097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: False, augmentations: True=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6671\n",
      "  Validation Loss: 0.6945\n",
      "  Validation Accuracy: 0.5180\n",
      "  Validation F1 Score: 0.4253\n",
      "  Validation AUC: 0.5515\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6364\n",
      "  Validation Loss: 0.6144\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.2646\n",
      "  Validation AUC: 0.5832\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6064\n",
      "  Validation Loss: 0.5948\n",
      "  Validation Accuracy: 0.7240\n",
      "  Validation F1 Score: 0.2857\n",
      "  Validation AUC: 0.6267\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5857\n",
      "  Validation Loss: 0.5907\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.2990\n",
      "  Validation AUC: 0.6427\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5788\n",
      "  Validation Loss: 0.5827\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3061\n",
      "  Validation AUC: 0.6549\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.5643\n",
      "  Validation Loss: 0.5790\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3383\n",
      "  Validation AUC: 0.6638\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5542\n",
      "  Validation Loss: 0.5804\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3911\n",
      "  Validation AUC: 0.6667\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5408\n",
      "  Validation Loss: 0.5752\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3761\n",
      "  Validation AUC: 0.6745\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5251\n",
      "  Validation Loss: 0.5746\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3784\n",
      "  Validation AUC: 0.6787\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5124\n",
      "  Validation Loss: 0.5778\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3930\n",
      "  Validation AUC: 0.6775\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7510\n",
      "  Validation Loss: 0.6373\n",
      "  Validation Accuracy: 0.6454\n",
      "  Validation F1 Score: 0.3071\n",
      "  Validation AUC: 0.5949\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6534\n",
      "  Validation Loss: 0.6381\n",
      "  Validation Accuracy: 0.6539\n",
      "  Validation F1 Score: 0.3849\n",
      "  Validation AUC: 0.6094\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5877\n",
      "  Validation Loss: 0.6177\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.3967\n",
      "  Validation AUC: 0.6262\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5352\n",
      "  Validation Loss: 0.5985\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.3717\n",
      "  Validation AUC: 0.6476\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4866\n",
      "  Validation Loss: 0.5970\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.3612\n",
      "  Validation AUC: 0.6441\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.4445\n",
      "  Validation Loss: 0.5960\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.4033\n",
      "  Validation AUC: 0.6547\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3909\n",
      "  Validation Loss: 0.5948\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3915\n",
      "  Validation AUC: 0.6596\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.3253\n",
      "  Validation Loss: 0.5972\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3750\n",
      "  Validation AUC: 0.6566\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.2734\n",
      "  Validation Loss: 0.6119\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3877\n",
      "  Validation AUC: 0.6621\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.2274\n",
      "  Validation Loss: 0.6306\n",
      "  Validation Accuracy: 0.7006\n",
      "  Validation F1 Score: 0.3896\n",
      "  Validation AUC: 0.6558\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6960\n",
      "  Validation Loss: 0.6745\n",
      "  Validation Accuracy: 0.5563\n",
      "  Validation F1 Score: 0.4367\n",
      "  Validation AUC: 0.5941\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6081\n",
      "  Validation Loss: 0.5965\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3085\n",
      "  Validation AUC: 0.6435\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5528\n",
      "  Validation Loss: 0.5825\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3184\n",
      "  Validation AUC: 0.6675\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5293\n",
      "  Validation Loss: 0.5735\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3030\n",
      "  Validation AUC: 0.6813\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4696\n",
      "  Validation Loss: 0.5702\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3251\n",
      "  Validation AUC: 0.6857\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.4429\n",
      "  Validation Loss: 0.5696\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.3909\n",
      "  Validation AUC: 0.6901\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3789\n",
      "  Validation Loss: 0.5720\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.4417\n",
      "  Validation AUC: 0.6941\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.3259\n",
      "  Validation Loss: 0.5723\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.4123\n",
      "  Validation AUC: 0.7003\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.2852\n",
      "  Validation Loss: 0.5796\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.4118\n",
      "  Validation AUC: 0.6962\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.8041\n",
      "  Validation Loss: 0.8183\n",
      "  Validation Accuracy: 0.3355\n",
      "  Validation F1 Score: 0.4686\n",
      "  Validation AUC: 0.5363\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.7239\n",
      "  Validation Loss: 0.6994\n",
      "  Validation Accuracy: 0.5265\n",
      "  Validation F1 Score: 0.4989\n",
      "  Validation AUC: 0.6163\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6788\n",
      "  Validation Loss: 0.6456\n",
      "  Validation Accuracy: 0.6200\n",
      "  Validation F1 Score: 0.4751\n",
      "  Validation AUC: 0.6588\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.6514\n",
      "  Validation Loss: 0.6246\n",
      "  Validation Accuracy: 0.6561\n",
      "  Validation F1 Score: 0.4706\n",
      "  Validation AUC: 0.6802\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.6276\n",
      "  Validation Loss: 0.5900\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.4380\n",
      "  Validation AUC: 0.6907\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.6054\n",
      "  Validation Loss: 0.5818\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.4167\n",
      "  Validation AUC: 0.6903\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5753\n",
      "  Validation Loss: 0.5679\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.3981\n",
      "  Validation AUC: 0.6935\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5813\n",
      "  Validation Loss: 0.5617\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4038\n",
      "  Validation AUC: 0.7029\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5722\n",
      "  Validation Loss: 0.5609\n",
      "  Validation Accuracy: 0.7282\n",
      "  Validation F1 Score: 0.4286\n",
      "  Validation AUC: 0.7027\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5594\n",
      "  Validation Loss: 0.5584\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4093\n",
      "  Validation AUC: 0.7038\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7531\n",
      "  Validation Loss: 0.6340\n",
      "  Validation Accuracy: 0.6815\n",
      "  Validation F1 Score: 0.1071\n",
      "  Validation AUC: 0.5180\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6999\n",
      "  Validation Loss: 0.6348\n",
      "  Validation Accuracy: 0.6539\n",
      "  Validation F1 Score: 0.3064\n",
      "  Validation AUC: 0.5929\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6484\n",
      "  Validation Loss: 0.6167\n",
      "  Validation Accuracy: 0.6773\n",
      "  Validation F1 Score: 0.3153\n",
      "  Validation AUC: 0.6140\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.6350\n",
      "  Validation Loss: 0.6006\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.3039\n",
      "  Validation AUC: 0.6298\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.6101\n",
      "  Validation Loss: 0.5971\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.2700\n",
      "  Validation AUC: 0.6356\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.6031\n",
      "  Validation Loss: 0.5900\n",
      "  Validation Accuracy: 0.7006\n",
      "  Validation F1 Score: 0.2985\n",
      "  Validation AUC: 0.6485\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5806\n",
      "  Validation Loss: 0.5863\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.3721\n",
      "  Validation AUC: 0.6576\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5869\n",
      "  Validation Loss: 0.5831\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3714\n",
      "  Validation AUC: 0.6649\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5586\n",
      "  Validation Loss: 0.5827\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.2902\n",
      "  Validation AUC: 0.6741\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define augmentations\n",
    "basic_augmentations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "no_augmentations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# try augmentations, use_scheduler, dropout_prob\n",
    "for dropout_prob in [0.3, 0.5]:\n",
    "    for augmentations in [no_augmentations, basic_augmentations]:\n",
    "        for use_scheduler in [True, False]:\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "            model = model.to(device)\n",
    "\n",
    "            print(f\"=====lr: {lr}, decay: {weight_decay}, dropout: {dropout_prob}, scheduler: {use_scheduler}, augmentations: {augmentations is not None}=====\")\n",
    "            train(model, train_loader, val_loader, lr, weight_decay, dropout_prob, use_scheduler, augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa941e-75ac-4240-a29f-842afee315b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#2700\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "model_vgg16.classifier[6] = torch.nn.Linear(model_vgg16.classifier[6].in_features, 1)\n",
    "model_vgg16 = model_vgg16.to(device)\n",
    "\n",
    "train(model_vgg16,train_loader,val_loader,1e-5,1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1bea07-61f1-40a9-aea3-fca7898a0655",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.7524\n",
      "  Validation Loss: 0.7403\n",
      "  Validation Accuracy: 0.3632\n",
      "  Validation F1 Score: 0.4772\n",
      "  Validation AUC: 0.5192\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.6062\n",
      "  Validation Loss: 0.6731\n",
      "  Validation Accuracy: 0.5812\n",
      "  Validation F1 Score: 0.3467\n",
      "  Validation AUC: 0.5837\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.4913\n",
      "  Validation Loss: 0.6254\n",
      "  Validation Accuracy: 0.6538\n",
      "  Validation F1 Score: 0.4000\n",
      "  Validation AUC: 0.6439\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.3666\n",
      "  Validation Loss: 0.6126\n",
      "  Validation Accuracy: 0.6752\n",
      "  Validation F1 Score: 0.4154\n",
      "  Validation AUC: 0.6478\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.2379\n",
      "  Validation Loss: 0.6077\n",
      "  Validation Accuracy: 0.6838\n",
      "  Validation F1 Score: 0.4127\n",
      "  Validation AUC: 0.6740\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.1357\n",
      "  Validation Loss: 0.6404\n",
      "  Validation Accuracy: 0.6838\n",
      "  Validation F1 Score: 0.4127\n",
      "  Validation AUC: 0.6597\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.0782\n",
      "  Validation Loss: 0.6699\n",
      "  Validation Accuracy: 0.6752\n",
      "  Validation F1 Score: 0.3871\n",
      "  Validation AUC: 0.6547\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.0536\n",
      "  Validation Loss: 0.6934\n",
      "  Validation Accuracy: 0.6752\n",
      "  Validation F1 Score: 0.3559\n",
      "  Validation AUC: 0.6605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-62982f69916c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_resnet50 = models.resnet50(pretrained=True)\n",
    "model_resnet50.fc = torch.nn.Linear(model_resnet50.fc.in_features, 1)\n",
    "model_resnet50 = model_resnet50.to(device)\n",
    "train(model_resnet50, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b5ea52d-fa75-45b8-b903-85cbc191a3d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.6694\n",
      "  Validation Loss: 0.6297\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.5891\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.5929\n",
      "  Validation Loss: 0.6126\n",
      "  Validation Accuracy: 0.6816\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.6218\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.5358\n",
      "  Validation Loss: 0.6018\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.0789\n",
      "  Validation AUC: 0.6409\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.4627\n",
      "  Validation Loss: 0.5883\n",
      "  Validation Accuracy: 0.6906\n",
      "  Validation F1 Score: 0.1882\n",
      "  Validation AUC: 0.6563\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.3654\n",
      "  Validation Loss: 0.5924\n",
      "  Validation Accuracy: 0.6906\n",
      "  Validation F1 Score: 0.2887\n",
      "  Validation AUC: 0.6588\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.2542\n",
      "  Validation Loss: 0.6177\n",
      "  Validation Accuracy: 0.6682\n",
      "  Validation F1 Score: 0.3509\n",
      "  Validation AUC: 0.6483\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.1620\n",
      "  Validation Loss: 0.6571\n",
      "  Validation Accuracy: 0.6278\n",
      "  Validation F1 Score: 0.3852\n",
      "  Validation AUC: 0.6354\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.1016\n",
      "  Validation Loss: 0.6942\n",
      "  Validation Accuracy: 0.6054\n",
      "  Validation F1 Score: 0.3803\n",
      "  Validation AUC: 0.6257\n",
      "Epoch 9/20:\n",
      "  Training Loss: 0.0696\n",
      "  Validation Loss: 0.7310\n",
      "  Validation Accuracy: 0.6099\n",
      "  Validation F1 Score: 0.4387\n",
      "  Validation AUC: 0.6282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d0b61d58d102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel_resnet50_unfreeze_last3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_resnet50_unfreeze_last3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_resnet50_unfreeze_last3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-fafe5f0ee0b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-f06e198245b6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pneumonia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \"\"\"\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_resnet50_unfreeze_last3 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replace the fully connected (fc) layer with your custom output layer\n",
    "model_resnet50_unfreeze_last3.fc = nn.Linear(model_resnet50_unfreeze_last3.fc.in_features, 1)\n",
    "\n",
    "# Freeze all layers except the last three\n",
    "for name, param in model_resnet50_unfreeze_last3.named_parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last three layers (you may adjust depending on the layer names)\n",
    "for name, param in model_resnet50_unfreeze_last3.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:  # Modify according to ResNet layer structure\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Move model to the device\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = PneumoniaDataset(train_df, transform)\n",
    "val_dataset = PneumoniaDataset(val_df, transform)\n",
    "#test_dataset = PneumoniaDataset(test_df, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "model_resnet50_unfreeze_last3 = model_resnet50_unfreeze_last3.to(device)\n",
    "train(model_resnet50_unfreeze_last3,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5611c21a-d547-4a25-9785-5f1c50eaff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x2ad37af76760>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f0885-5fd3-43e0-b4a9-6fa98aff452c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
