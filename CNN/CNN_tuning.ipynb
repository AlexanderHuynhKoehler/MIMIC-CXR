{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef5622e-8382-43fa-a28e-962c0216dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f289253-d55d-49e4-a928-362efd649d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('cxr-record-list.csv')\n",
    "df4 = pd.read_csv('mimic-cxr-2.0.0-chexpert.csv')\n",
    "df6 = pd.read_csv('mimic-cxr-2.0.0-metadata.csv')\n",
    "merge_df = df2.merge(df4,on=['subject_id','study_id'],how='inner')\n",
    "merge_df = merge_df.merge(df6[['dicom_id', 'ViewPosition']],on='dicom_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9e2c41-f0b7-41a4-8646-7f1f1429c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_train_val(df,img_path,disease):\n",
    "    '''\n",
    "    split data to train ans validation\n",
    "    disease labe must be 1 for case or 0 for control, labeled by chexpert\n",
    "    images are all posterior to anterior (filtered when downloading)\n",
    "    choose one PA image per subject\n",
    "    '''\n",
    "    file_ids = [file.replace(\".jpg\",\"\") for file in os.listdir(img_path)]\n",
    "    df = df[df['dicom_id'].isin(file_ids)]\n",
    "    \n",
    "    df.loc[:,'image_path'] = img_path+ '/' + df['dicom_id'] + '.jpg'\n",
    "    \n",
    "    input_df = df[df[disease].isin([0,1])].drop_duplicates('subject_id')\n",
    "    train_df, val_df = train_test_split(\n",
    "        input_df, \n",
    "        test_size=0.2, \n",
    "        random_state=1, \n",
    "        stratify=input_df[disease]\n",
    "    )\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fefc441-ab0c-4153-9cf7-3a872bf45190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the custom dataset class\n",
    "class disease_Dataset(Dataset):\n",
    "    def __init__(self, df, disease, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.disease = disease\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert(\"RGB\") #images are gray scale, but models require RGB\n",
    "        label = torch.tensor(row[self.disease], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def generate_dataLoader(disease, train_df,val_df):\n",
    "    # DataLoaders\n",
    "    train_dataset = disease_Dataset(train_df,disease, transform)\n",
    "    val_dataset = disease_Dataset(val_df,disease, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896aa03a-0ce5-4a86-96ac-0390d8e4b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, lr, weight_decay):\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    num_epochs = 10\n",
    "    patience = 3  # Number of epochs to wait for improvement\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "        val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "        val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"  Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0  # Reset counter if validation loss improves\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe789b4-9ee3-40f7-afb0-d48583455d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = csv_to_train_val(merge_df,'images_NEW','Pneumonia') #2700\n",
    "train_loader, val_loader = generate_dataLoader('Pneumonia',train_df,val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fc2466a-acdb-4fcc-8ccf-2abface6ec25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.9771\n",
      "  Validation Loss: 0.8893\n",
      "  Validation Accuracy: 0.3025\n",
      "  Validation F1 Score: 0.4378\n",
      "  Validation AUC: 0.5210\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.8454\n",
      "  Validation Loss: 0.8999\n",
      "  Validation Accuracy: 0.3086\n",
      "  Validation F1 Score: 0.4343\n",
      "  Validation AUC: 0.5570\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.7504\n",
      "  Validation Loss: 0.8781\n",
      "  Validation Accuracy: 0.3457\n",
      "  Validation F1 Score: 0.4536\n",
      "  Validation AUC: 0.5857\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.6630\n",
      "  Validation Loss: 0.8257\n",
      "  Validation Accuracy: 0.4074\n",
      "  Validation F1 Score: 0.4419\n",
      "  Validation AUC: 0.5614\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.5783\n",
      "  Validation Loss: 0.8266\n",
      "  Validation Accuracy: 0.4321\n",
      "  Validation F1 Score: 0.4321\n",
      "  Validation AUC: 0.5437\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.5061\n",
      "  Validation Loss: 0.7849\n",
      "  Validation Accuracy: 0.4691\n",
      "  Validation F1 Score: 0.3768\n",
      "  Validation AUC: 0.5416\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.4278\n",
      "  Validation Loss: 0.8137\n",
      "  Validation Accuracy: 0.4444\n",
      "  Validation F1 Score: 0.3662\n",
      "  Validation AUC: 0.5376\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.3636\n",
      "  Validation Loss: 0.7763\n",
      "  Validation Accuracy: 0.5247\n",
      "  Validation F1 Score: 0.3740\n",
      "  Validation AUC: 0.5381\n",
      "Epoch 9/20:\n",
      "  Training Loss: 0.2973\n",
      "  Validation Loss: 0.7981\n",
      "  Validation Accuracy: 0.5247\n",
      "  Validation F1 Score: 0.3740\n",
      "  Validation AUC: 0.5383\n",
      "Epoch 10/20:\n",
      "  Training Loss: 0.2500\n",
      "  Validation Loss: 0.7652\n",
      "  Validation Accuracy: 0.5679\n",
      "  Validation F1 Score: 0.3636\n",
      "  Validation AUC: 0.5399\n",
      "Epoch 11/20:\n",
      "  Training Loss: 0.1939\n",
      "  Validation Loss: 0.7756\n",
      "  Validation Accuracy: 0.5802\n",
      "  Validation F1 Score: 0.3585\n",
      "  Validation AUC: 0.5435\n",
      "Epoch 12/20:\n",
      "  Training Loss: 0.1621\n",
      "  Validation Loss: 0.8081\n",
      "  Validation Accuracy: 0.5802\n",
      "  Validation F1 Score: 0.3818\n",
      "  Validation AUC: 0.5447\n",
      "Epoch 13/20:\n",
      "  Training Loss: 0.1242\n",
      "  Validation Loss: 0.7810\n",
      "  Validation Accuracy: 0.6049\n",
      "  Validation F1 Score: 0.3600\n",
      "  Validation AUC: 0.5582\n",
      "Epoch 14/20:\n",
      "  Training Loss: 0.1062\n",
      "  Validation Loss: 0.7861\n",
      "  Validation Accuracy: 0.6358\n",
      "  Validation F1 Score: 0.3789\n",
      "  Validation AUC: 0.5570\n",
      "Epoch 15/20:\n",
      "  Training Loss: 0.0793\n",
      "  Validation Loss: 0.7896\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3830\n",
      "  Validation AUC: 0.5572\n",
      "Epoch 16/20:\n",
      "  Training Loss: 0.0672\n",
      "  Validation Loss: 0.7821\n",
      "  Validation Accuracy: 0.6543\n",
      "  Validation F1 Score: 0.3913\n",
      "  Validation AUC: 0.5559\n",
      "Epoch 17/20:\n",
      "  Training Loss: 0.0580\n",
      "  Validation Loss: 0.8070\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3696\n",
      "  Validation AUC: 0.5661\n",
      "Epoch 18/20:\n",
      "  Training Loss: 0.0569\n",
      "  Validation Loss: 0.8455\n",
      "  Validation Accuracy: 0.6358\n",
      "  Validation F1 Score: 0.3918\n",
      "  Validation AUC: 0.5686\n",
      "Epoch 19/20:\n",
      "  Training Loss: 0.0468\n",
      "  Validation Loss: 0.8148\n",
      "  Validation Accuracy: 0.6420\n",
      "  Validation F1 Score: 0.3830\n",
      "  Validation AUC: 0.5676\n",
      "Epoch 20/20:\n",
      "  Training Loss: 0.0603\n",
      "  Validation Loss: 0.8120\n",
      "  Validation Accuracy: 0.6543\n",
      "  Validation F1 Score: 0.3636\n",
      "  Validation AUC: 0.5680\n",
      "CPU times: user 59min 28s, sys: 25.1 s, total: 59min 53s\n",
      "Wall time: 1h 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4700 1 & all 0\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a7ecf4-21de-4f26-af50-3f608260ba96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "  Training Loss: 0.6381\n",
      "  Validation Loss: 0.6231\n",
      "  Validation Accuracy: 0.6916\n",
      "  Validation F1 Score: 0.2353\n",
      "  Validation AUC: 0.6292\n",
      "Epoch 2/20:\n",
      "  Training Loss: 0.5734\n",
      "  Validation Loss: 0.5982\n",
      "  Validation Accuracy: 0.6843\n",
      "  Validation F1 Score: 0.0942\n",
      "  Validation AUC: 0.6561\n",
      "Epoch 3/20:\n",
      "  Training Loss: 0.5273\n",
      "  Validation Loss: 0.5896\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.1224\n",
      "  Validation AUC: 0.6706\n",
      "Epoch 4/20:\n",
      "  Training Loss: 0.4814\n",
      "  Validation Loss: 0.5820\n",
      "  Validation Accuracy: 0.6788\n",
      "  Validation F1 Score: 0.1776\n",
      "  Validation AUC: 0.6843\n",
      "Epoch 5/20:\n",
      "  Training Loss: 0.4316\n",
      "  Validation Loss: 0.5822\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.2110\n",
      "  Validation AUC: 0.6785\n",
      "Epoch 6/20:\n",
      "  Training Loss: 0.3786\n",
      "  Validation Loss: 0.5786\n",
      "  Validation Accuracy: 0.6898\n",
      "  Validation F1 Score: 0.3254\n",
      "  Validation AUC: 0.6876\n",
      "Epoch 7/20:\n",
      "  Training Loss: 0.3127\n",
      "  Validation Loss: 0.5928\n",
      "  Validation Accuracy: 0.6953\n",
      "  Validation F1 Score: 0.3128\n",
      "  Validation AUC: 0.6697\n",
      "Epoch 8/20:\n",
      "  Training Loss: 0.2475\n",
      "  Validation Loss: 0.6080\n",
      "  Validation Accuracy: 0.6880\n",
      "  Validation F1 Score: 0.3498\n",
      "  Validation AUC: 0.6576\n",
      "Epoch 9/20:\n",
      "  Training Loss: 0.1798\n",
      "  Validation Loss: 0.6366\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.3813\n",
      "  Validation AUC: 0.6488\n",
      "Epoch 10/20:\n",
      "  Training Loss: 0.1301\n",
      "  Validation Loss: 0.6653\n",
      "  Validation Accuracy: 0.6606\n",
      "  Validation F1 Score: 0.4076\n",
      "  Validation AUC: 0.6390\n",
      "Epoch 11/20:\n",
      "  Training Loss: 0.0902\n",
      "  Validation Loss: 0.7034\n",
      "  Validation Accuracy: 0.6770\n",
      "  Validation F1 Score: 0.3610\n",
      "  Validation AUC: 0.6377\n",
      "Epoch 12/20:\n",
      "  Training Loss: 0.0658\n",
      "  Validation Loss: 0.7323\n",
      "  Validation Accuracy: 0.6478\n",
      "  Validation F1 Score: 0.4134\n",
      "  Validation AUC: 0.6280\n",
      "Epoch 13/20:\n",
      "  Training Loss: 0.0503\n",
      "  Validation Loss: 0.7479\n",
      "  Validation Accuracy: 0.6624\n",
      "  Validation F1 Score: 0.3771\n",
      "  Validation AUC: 0.6351\n",
      "Epoch 14/20:\n",
      "  Training Loss: 0.0380\n",
      "  Validation Loss: 0.7797\n",
      "  Validation Accuracy: 0.6752\n",
      "  Validation F1 Score: 0.3946\n",
      "  Validation AUC: 0.6289\n",
      "Epoch 15/20:\n",
      "  Training Loss: 0.0321\n",
      "  Validation Loss: 0.8122\n",
      "  Validation Accuracy: 0.6423\n",
      "  Validation F1 Score: 0.4432\n",
      "  Validation AUC: 0.6235\n",
      "Epoch 16/20:\n",
      "  Training Loss: 0.0284\n",
      "  Validation Loss: 0.8237\n",
      "  Validation Accuracy: 0.6405\n",
      "  Validation F1 Score: 0.4223\n",
      "  Validation AUC: 0.6351\n",
      "Epoch 17/20:\n",
      "  Training Loss: 0.0246\n",
      "  Validation Loss: 0.8643\n",
      "  Validation Accuracy: 0.6551\n",
      "  Validation F1 Score: 0.3762\n",
      "  Validation AUC: 0.6162\n",
      "Epoch 18/20:\n",
      "  Training Loss: 0.0191\n",
      "  Validation Loss: 0.8738\n",
      "  Validation Accuracy: 0.6533\n",
      "  Validation F1 Score: 0.3791\n",
      "  Validation AUC: 0.6195\n",
      "Epoch 19/20:\n",
      "  Training Loss: 0.0169\n",
      "  Validation Loss: 0.8942\n",
      "  Validation Accuracy: 0.6569\n",
      "  Validation F1 Score: 0.4051\n",
      "  Validation AUC: 0.6157\n",
      "Epoch 20/20:\n",
      "  Training Loss: 0.0148\n",
      "  Validation Loss: 0.9292\n",
      "  Validation Accuracy: 0.6697\n",
      "  Validation F1 Score: 0.3604\n",
      "  Validation AUC: 0.6138\n",
      "CPU times: user 1h 32min 16s, sys: 46.9 s, total: 1h 33min 3s\n",
      "Wall time: 1h 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "model = model.to(device)\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cfcd8bb-f0e1-486b-b345-0663575cd01c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6382\n",
      "  Validation Loss: 0.5733\n",
      "  Validation Accuracy: 0.6861\n",
      "  Validation F1 Score: 0.0278\n",
      "  Validation AUC: 0.7130\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.2959\n",
      "  Validation Loss: 0.6541\n",
      "  Validation Accuracy: 0.7309\n",
      "  Validation F1 Score: 0.2683\n",
      "  Validation AUC: 0.7170\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.0847\n",
      "  Validation Loss: 0.5407\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5045\n",
      "  Validation AUC: 0.7738\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0230\n",
      "  Validation Loss: 0.6324\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5133\n",
      "  Validation AUC: 0.7545\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.0078\n",
      "  Validation Loss: 0.6623\n",
      "  Validation Accuracy: 0.7489\n",
      "  Validation F1 Score: 0.4717\n",
      "  Validation AUC: 0.7755\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.0059\n",
      "  Validation Loss: 0.6439\n",
      "  Validation Accuracy: 0.7623\n",
      "  Validation F1 Score: 0.5310\n",
      "  Validation AUC: 0.7810\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.0041\n",
      "  Validation Loss: 0.6519\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.5133\n",
      "  Validation AUC: 0.7808\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.0028\n",
      "  Validation Loss: 0.6748\n",
      "  Validation Accuracy: 0.7534\n",
      "  Validation F1 Score: 0.4860\n",
      "  Validation AUC: 0.7816\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.0018\n",
      "  Validation Loss: 0.7044\n",
      "  Validation Accuracy: 0.7578\n",
      "  Validation F1 Score: 0.4906\n",
      "  Validation AUC: 0.7796\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.0020\n",
      "  Validation Loss: 0.6936\n",
      "  Validation Accuracy: 0.7623\n",
      "  Validation F1 Score: 0.5225\n",
      "  Validation AUC: 0.7840\n",
      "CPU times: user 18min 9s, sys: 19.6 s, total: 18min 28s\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Define ResNet model\n",
    "model_resnet = models.resnet18(pretrained=True)\n",
    "model_resnet.fc = torch.nn.Linear(model_resnet.fc.in_features, 1)\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_resnet(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    model_resnet.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_resnet(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(val_dataset)\n",
    "\n",
    "    # Validation metrics\n",
    "    val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "    val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "    val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"  Validation AUC: {val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f252e-75dc-4514-b43d-eaa8f54bdc4b",
   "metadata": {},
   "source": [
    "## hyper parameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d71dde6-9dc5-4fe4-ad89-fcdcadd66a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.001, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6479\n",
      "  Validation Loss: 0.5885\n",
      "  Validation Accuracy: 0.6837\n",
      "  Validation F1 Score: 0.4335\n",
      "  Validation AUC: 0.6721\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5862\n",
      "  Validation Loss: 0.6640\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.0654\n",
      "  Validation AUC: 0.6549\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5766\n",
      "  Validation Loss: 0.6036\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3470\n",
      "  Validation AUC: 0.6305\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5580\n",
      "  Validation Loss: 0.6936\n",
      "  Validation Accuracy: 0.6263\n",
      "  Validation F1 Score: 0.4172\n",
      "  Validation AUC: 0.6166\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.001, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6562\n",
      "  Validation Loss: 0.6730\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.6546\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5940\n",
      "  Validation Loss: 0.5925\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.0270\n",
      "  Validation AUC: 0.6361\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5759\n",
      "  Validation Loss: 0.6244\n",
      "  Validation Accuracy: 0.6794\n",
      "  Validation F1 Score: 0.2775\n",
      "  Validation AUC: 0.6198\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5564\n",
      "  Validation Loss: 0.6064\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.1006\n",
      "  Validation AUC: 0.6587\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5300\n",
      "  Validation Loss: 0.6357\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.1538\n",
      "  Validation AUC: 0.6659\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.0001, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6217\n",
      "  Validation Loss: 0.5791\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.2932\n",
      "  Validation AUC: 0.6840\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.3187\n",
      "  Validation Loss: 0.6597\n",
      "  Validation Accuracy: 0.6773\n",
      "  Validation F1 Score: 0.4062\n",
      "  Validation AUC: 0.6484\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.0957\n",
      "  Validation Loss: 0.7291\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.4146\n",
      "  Validation AUC: 0.6884\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0306\n",
      "  Validation Loss: 0.8418\n",
      "  Validation Accuracy: 0.6582\n",
      "  Validation F1 Score: 0.4059\n",
      "  Validation AUC: 0.6563\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 0.0001, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6116\n",
      "  Validation Loss: 0.5780\n",
      "  Validation Accuracy: 0.6858\n",
      "  Validation F1 Score: 0.3934\n",
      "  Validation AUC: 0.6989\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.3569\n",
      "  Validation Loss: 0.8998\n",
      "  Validation Accuracy: 0.5605\n",
      "  Validation F1 Score: 0.4733\n",
      "  Validation AUC: 0.6241\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.1057\n",
      "  Validation Loss: 0.8787\n",
      "  Validation Accuracy: 0.6242\n",
      "  Validation F1 Score: 0.3218\n",
      "  Validation AUC: 0.6184\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.0371\n",
      "  Validation Loss: 0.9318\n",
      "  Validation Accuracy: 0.6561\n",
      "  Validation F1 Score: 0.4214\n",
      "  Validation AUC: 0.6525\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6331\n",
      "  Validation Loss: 0.6678\n",
      "  Validation Accuracy: 0.5732\n",
      "  Validation F1 Score: 0.3964\n",
      "  Validation AUC: 0.5753\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5443\n",
      "  Validation Loss: 0.5810\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.2474\n",
      "  Validation AUC: 0.6737\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.4797\n",
      "  Validation Loss: 0.5750\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.3514\n",
      "  Validation AUC: 0.6871\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4165\n",
      "  Validation Loss: 0.5719\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3529\n",
      "  Validation AUC: 0.6894\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.3515\n",
      "  Validation Loss: 0.5710\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.4034\n",
      "  Validation AUC: 0.6972\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.2837\n",
      "  Validation Loss: 0.5739\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3966\n",
      "  Validation AUC: 0.6991\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2222\n",
      "  Validation Loss: 0.5829\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.4132\n",
      "  Validation AUC: 0.6998\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.1614\n",
      "  Validation Loss: 0.6026\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.4257\n",
      "  Validation AUC: 0.6918\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6431\n",
      "  Validation Loss: 0.6199\n",
      "  Validation Accuracy: 0.6794\n",
      "  Validation F1 Score: 0.2775\n",
      "  Validation AUC: 0.6321\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5512\n",
      "  Validation Loss: 0.5753\n",
      "  Validation Accuracy: 0.7325\n",
      "  Validation F1 Score: 0.3762\n",
      "  Validation AUC: 0.6915\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.4813\n",
      "  Validation Loss: 0.5634\n",
      "  Validation Accuracy: 0.7282\n",
      "  Validation F1 Score: 0.3786\n",
      "  Validation AUC: 0.7056\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4186\n",
      "  Validation Loss: 0.5555\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3889\n",
      "  Validation AUC: 0.7154\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.3514\n",
      "  Validation Loss: 0.5537\n",
      "  Validation Accuracy: 0.7346\n",
      "  Validation F1 Score: 0.4541\n",
      "  Validation AUC: 0.7179\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.2820\n",
      "  Validation Loss: 0.5543\n",
      "  Validation Accuracy: 0.7346\n",
      "  Validation F1 Score: 0.4541\n",
      "  Validation AUC: 0.7172\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2240\n",
      "  Validation Loss: 0.5661\n",
      "  Validation Accuracy: 0.7261\n",
      "  Validation F1 Score: 0.4416\n",
      "  Validation AUC: 0.7094\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.1629\n",
      "  Validation Loss: 0.5739\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.4585\n",
      "  Validation AUC: 0.7092\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "# try learning rate and weight dacay\n",
    "for lr in [1e-3, 1e-4, 1e-5]:\n",
    "    for weight_decay in [0, 1e-4]:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "        model = model.to(device)\n",
    "        print(f\"=====lr: {lr}, decay: {weight_decay}=====\")\n",
    "        train(model, train_loader, val_loader, lr, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205f8efc-09af-4c3f-b1dd-e92a5921d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, lr=1e-5, weight_decay=1e-4, dropout_prob=0.5, use_scheduler=True, augmentations=None):\n",
    "\n",
    "    # Apply augmentations if provided\n",
    "    if augmentations:\n",
    "        train_loader.dataset.transform = augmentations\n",
    "\n",
    "    # Add dropout to the fully connected layer dynamically\n",
    "    model.fc = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(p=dropout_prob),\n",
    "        torch.nn.Linear(model.fc.in_features, 1)\n",
    "    ).to(device)  # Ensure the modified layer is on the correct device\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Optionally use a learning rate scheduler\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.1, patience=2, verbose=True\n",
    "        )\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    num_epochs = 10\n",
    "    patience = 3  # Number of epochs to wait for improvement\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # Move images and labels to the specified device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                # Move images and labels to the specified device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()  # Move predictions to CPU for evaluation\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())  # Move labels to CPU for evaluation\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_binary_preds = [1 if p > 0.5 else 0 for p in val_preds]\n",
    "        val_accuracy = accuracy_score(val_labels, val_binary_preds)\n",
    "        val_f1 = f1_score(val_labels, val_binary_preds)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Training Loss: {epoch_train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {epoch_val_loss:.4f}\")\n",
    "        print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"  Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Update the learning rate scheduler\n",
    "        if use_scheduler:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "\n",
    "        # Check for early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0  # Reset counter if validation loss improves\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b980234-ece1-4a52-ac6c-8d98bc7f6e95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: True, augmentations: True=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6602\n",
      "  Validation Loss: 0.6042\n",
      "  Validation Accuracy: 0.6858\n",
      "  Validation F1 Score: 0.0864\n",
      "  Validation AUC: 0.6128\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5814\n",
      "  Validation Loss: 0.5913\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.3408\n",
      "  Validation AUC: 0.6699\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5214\n",
      "  Validation Loss: 0.5816\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.3498\n",
      "  Validation AUC: 0.6796\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4651\n",
      "  Validation Loss: 0.5717\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3839\n",
      "  Validation AUC: 0.6937\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4134\n",
      "  Validation Loss: 0.5701\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3805\n",
      "  Validation AUC: 0.6957\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.3533\n",
      "  Validation Loss: 0.5745\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.3739\n",
      "  Validation AUC: 0.6950\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3006\n",
      "  Validation Loss: 0.5758\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.4418\n",
      "  Validation AUC: 0.7012\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.2361\n",
      "  Validation Loss: 0.5874\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.4688\n",
      "  Validation AUC: 0.6990\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7568\n",
      "  Validation Loss: 0.7303\n",
      "  Validation Accuracy: 0.4671\n",
      "  Validation F1 Score: 0.4803\n",
      "  Validation AUC: 0.6101\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6377\n",
      "  Validation Loss: 0.6509\n",
      "  Validation Accuracy: 0.6093\n",
      "  Validation F1 Score: 0.4945\n",
      "  Validation AUC: 0.6465\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5570\n",
      "  Validation Loss: 0.6144\n",
      "  Validation Accuracy: 0.6688\n",
      "  Validation F1 Score: 0.4429\n",
      "  Validation AUC: 0.6649\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.4867\n",
      "  Validation Loss: 0.6015\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.4535\n",
      "  Validation AUC: 0.6695\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4216\n",
      "  Validation Loss: 0.5849\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.4498\n",
      "  Validation AUC: 0.6810\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.3636\n",
      "  Validation Loss: 0.5917\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.4689\n",
      "  Validation AUC: 0.6837\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.2949\n",
      "  Validation Loss: 0.5837\n",
      "  Validation Accuracy: 0.7261\n",
      "  Validation F1 Score: 0.4735\n",
      "  Validation AUC: 0.6814\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.2342\n",
      "  Validation Loss: 0.5967\n",
      "  Validation Accuracy: 0.7240\n",
      "  Validation F1 Score: 0.4758\n",
      "  Validation AUC: 0.6814\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.1762\n",
      "  Validation Loss: 0.6243\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.4794\n",
      "  Validation AUC: 0.6755\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.1363\n",
      "  Validation Loss: 0.6586\n",
      "  Validation Accuracy: 0.6879\n",
      "  Validation F1 Score: 0.4983\n",
      "  Validation AUC: 0.6760\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6791\n",
      "  Validation Loss: 0.6387\n",
      "  Validation Accuracy: 0.6454\n",
      "  Validation F1 Score: 0.2304\n",
      "  Validation AUC: 0.5650\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6329\n",
      "  Validation Loss: 0.6015\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3349\n",
      "  Validation AUC: 0.6514\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6034\n",
      "  Validation Loss: 0.5901\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3704\n",
      "  Validation AUC: 0.6688\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5981\n",
      "  Validation Loss: 0.5778\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3491\n",
      "  Validation AUC: 0.6870\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5770\n",
      "  Validation Loss: 0.5691\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.3147\n",
      "  Validation AUC: 0.6949\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.5714\n",
      "  Validation Loss: 0.5660\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3512\n",
      "  Validation AUC: 0.6973\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5516\n",
      "  Validation Loss: 0.5649\n",
      "  Validation Accuracy: 0.7219\n",
      "  Validation F1 Score: 0.3732\n",
      "  Validation AUC: 0.6977\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5461\n",
      "  Validation Loss: 0.5638\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3592\n",
      "  Validation AUC: 0.7016\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5328\n",
      "  Validation Loss: 0.5611\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4093\n",
      "  Validation AUC: 0.7038\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5087\n",
      "  Validation Loss: 0.5624\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3575\n",
      "  Validation AUC: 0.7097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.3, scheduler: False, augmentations: True=====\n",
      "Epoch 1/10:\n",
      "  Training Loss: 0.6671\n",
      "  Validation Loss: 0.6945\n",
      "  Validation Accuracy: 0.5180\n",
      "  Validation F1 Score: 0.4253\n",
      "  Validation AUC: 0.5515\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6364\n",
      "  Validation Loss: 0.6144\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.2646\n",
      "  Validation AUC: 0.5832\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6064\n",
      "  Validation Loss: 0.5948\n",
      "  Validation Accuracy: 0.7240\n",
      "  Validation F1 Score: 0.2857\n",
      "  Validation AUC: 0.6267\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5857\n",
      "  Validation Loss: 0.5907\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.2990\n",
      "  Validation AUC: 0.6427\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.5788\n",
      "  Validation Loss: 0.5827\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3061\n",
      "  Validation AUC: 0.6549\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.5643\n",
      "  Validation Loss: 0.5790\n",
      "  Validation Accuracy: 0.7176\n",
      "  Validation F1 Score: 0.3383\n",
      "  Validation AUC: 0.6638\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5542\n",
      "  Validation Loss: 0.5804\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3911\n",
      "  Validation AUC: 0.6667\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5408\n",
      "  Validation Loss: 0.5752\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.3761\n",
      "  Validation AUC: 0.6745\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5251\n",
      "  Validation Loss: 0.5746\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3784\n",
      "  Validation AUC: 0.6787\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5124\n",
      "  Validation Loss: 0.5778\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3930\n",
      "  Validation AUC: 0.6775\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7510\n",
      "  Validation Loss: 0.6373\n",
      "  Validation Accuracy: 0.6454\n",
      "  Validation F1 Score: 0.3071\n",
      "  Validation AUC: 0.5949\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6534\n",
      "  Validation Loss: 0.6381\n",
      "  Validation Accuracy: 0.6539\n",
      "  Validation F1 Score: 0.3849\n",
      "  Validation AUC: 0.6094\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5877\n",
      "  Validation Loss: 0.6177\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.3967\n",
      "  Validation AUC: 0.6262\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5352\n",
      "  Validation Loss: 0.5985\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.3717\n",
      "  Validation AUC: 0.6476\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4866\n",
      "  Validation Loss: 0.5970\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.3612\n",
      "  Validation AUC: 0.6441\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.4445\n",
      "  Validation Loss: 0.5960\n",
      "  Validation Accuracy: 0.6921\n",
      "  Validation F1 Score: 0.4033\n",
      "  Validation AUC: 0.6547\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3909\n",
      "  Validation Loss: 0.5948\n",
      "  Validation Accuracy: 0.6964\n",
      "  Validation F1 Score: 0.3915\n",
      "  Validation AUC: 0.6596\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.3253\n",
      "  Validation Loss: 0.5972\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.3750\n",
      "  Validation AUC: 0.6566\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.2734\n",
      "  Validation Loss: 0.6119\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3877\n",
      "  Validation AUC: 0.6621\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.2274\n",
      "  Validation Loss: 0.6306\n",
      "  Validation Accuracy: 0.7006\n",
      "  Validation F1 Score: 0.3896\n",
      "  Validation AUC: 0.6558\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6960\n",
      "  Validation Loss: 0.6745\n",
      "  Validation Accuracy: 0.5563\n",
      "  Validation F1 Score: 0.4367\n",
      "  Validation AUC: 0.5941\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6081\n",
      "  Validation Loss: 0.5965\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.3085\n",
      "  Validation AUC: 0.6435\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5528\n",
      "  Validation Loss: 0.5825\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3184\n",
      "  Validation AUC: 0.6675\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5293\n",
      "  Validation Loss: 0.5735\n",
      "  Validation Accuracy: 0.7070\n",
      "  Validation F1 Score: 0.3030\n",
      "  Validation AUC: 0.6813\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4696\n",
      "  Validation Loss: 0.5702\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.3251\n",
      "  Validation AUC: 0.6857\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.4429\n",
      "  Validation Loss: 0.5696\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.3909\n",
      "  Validation AUC: 0.6901\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.3789\n",
      "  Validation Loss: 0.5720\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.4417\n",
      "  Validation AUC: 0.6941\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.3259\n",
      "  Validation Loss: 0.5723\n",
      "  Validation Accuracy: 0.7155\n",
      "  Validation F1 Score: 0.4123\n",
      "  Validation AUC: 0.7003\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.2852\n",
      "  Validation Loss: 0.5796\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.4118\n",
      "  Validation AUC: 0.6962\n",
      "Early stopping triggered. Stopping training.\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: True, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.8041\n",
      "  Validation Loss: 0.8183\n",
      "  Validation Accuracy: 0.3355\n",
      "  Validation F1 Score: 0.4686\n",
      "  Validation AUC: 0.5363\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.7239\n",
      "  Validation Loss: 0.6994\n",
      "  Validation Accuracy: 0.5265\n",
      "  Validation F1 Score: 0.4989\n",
      "  Validation AUC: 0.6163\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6788\n",
      "  Validation Loss: 0.6456\n",
      "  Validation Accuracy: 0.6200\n",
      "  Validation F1 Score: 0.4751\n",
      "  Validation AUC: 0.6588\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.6514\n",
      "  Validation Loss: 0.6246\n",
      "  Validation Accuracy: 0.6561\n",
      "  Validation F1 Score: 0.4706\n",
      "  Validation AUC: 0.6802\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.6276\n",
      "  Validation Loss: 0.5900\n",
      "  Validation Accuracy: 0.7113\n",
      "  Validation F1 Score: 0.4380\n",
      "  Validation AUC: 0.6907\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.6054\n",
      "  Validation Loss: 0.5818\n",
      "  Validation Accuracy: 0.7028\n",
      "  Validation F1 Score: 0.4167\n",
      "  Validation AUC: 0.6903\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5753\n",
      "  Validation Loss: 0.5679\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.3981\n",
      "  Validation AUC: 0.6935\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5813\n",
      "  Validation Loss: 0.5617\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4038\n",
      "  Validation AUC: 0.7029\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5722\n",
      "  Validation Loss: 0.5609\n",
      "  Validation Accuracy: 0.7282\n",
      "  Validation F1 Score: 0.4286\n",
      "  Validation AUC: 0.7027\n",
      "Epoch 10/10:\n",
      "  Training Loss: 0.5594\n",
      "  Validation Loss: 0.5584\n",
      "  Validation Accuracy: 0.7304\n",
      "  Validation F1 Score: 0.4093\n",
      "  Validation AUC: 0.7038\n",
      "=====lr: 1e-05, decay: 0.0001, dropout: 0.5, scheduler: False, augmentations: True=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.7531\n",
      "  Validation Loss: 0.6340\n",
      "  Validation Accuracy: 0.6815\n",
      "  Validation F1 Score: 0.1071\n",
      "  Validation AUC: 0.5180\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.6999\n",
      "  Validation Loss: 0.6348\n",
      "  Validation Accuracy: 0.6539\n",
      "  Validation F1 Score: 0.3064\n",
      "  Validation AUC: 0.5929\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.6484\n",
      "  Validation Loss: 0.6167\n",
      "  Validation Accuracy: 0.6773\n",
      "  Validation F1 Score: 0.3153\n",
      "  Validation AUC: 0.6140\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.6350\n",
      "  Validation Loss: 0.6006\n",
      "  Validation Accuracy: 0.6985\n",
      "  Validation F1 Score: 0.3039\n",
      "  Validation AUC: 0.6298\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.6101\n",
      "  Validation Loss: 0.5971\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.2700\n",
      "  Validation AUC: 0.6356\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.6031\n",
      "  Validation Loss: 0.5900\n",
      "  Validation Accuracy: 0.7006\n",
      "  Validation F1 Score: 0.2985\n",
      "  Validation AUC: 0.6485\n",
      "Epoch 7/10:\n",
      "  Training Loss: 0.5806\n",
      "  Validation Loss: 0.5863\n",
      "  Validation Accuracy: 0.7134\n",
      "  Validation F1 Score: 0.3721\n",
      "  Validation AUC: 0.6576\n",
      "Epoch 8/10:\n",
      "  Training Loss: 0.5869\n",
      "  Validation Loss: 0.5831\n",
      "  Validation Accuracy: 0.7197\n",
      "  Validation F1 Score: 0.3714\n",
      "  Validation AUC: 0.6649\n",
      "Epoch 9/10:\n",
      "  Training Loss: 0.5586\n",
      "  Validation Loss: 0.5827\n",
      "  Validation Accuracy: 0.7091\n",
      "  Validation F1 Score: 0.2902\n",
      "  Validation AUC: 0.6741\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define augmentations\n",
    "basic_augmentations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "no_augmentations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# try augmentations, use_scheduler, dropout_prob\n",
    "for dropout_prob in [0.3, 0.5]:\n",
    "    for augmentations in [no_augmentations, basic_augmentations]:\n",
    "        for use_scheduler in [True, False]:\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "            model = model.to(device)\n",
    "\n",
    "            print(f\"=====lr: {lr}, decay: {weight_decay}, dropout: {dropout_prob}, scheduler: {use_scheduler}, augmentations: {augmentations is not None}=====\")\n",
    "            train(model, train_loader, val_loader, lr, weight_decay, dropout_prob, use_scheduler, augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48aa941e-75ac-4240-a29f-842afee315b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hsieh.fe/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Training Loss: 0.6361\n",
      "  Validation Loss: 0.6047\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.6342\n",
      "Epoch 2/10:\n",
      "  Training Loss: 0.5986\n",
      "  Validation Loss: 0.5967\n",
      "  Validation Accuracy: 0.6900\n",
      "  Validation F1 Score: 0.0000\n",
      "  Validation AUC: 0.6488\n",
      "Epoch 3/10:\n",
      "  Training Loss: 0.5717\n",
      "  Validation Loss: 0.5891\n",
      "  Validation Accuracy: 0.6943\n",
      "  Validation F1 Score: 0.0649\n",
      "  Validation AUC: 0.6494\n",
      "Epoch 4/10:\n",
      "  Training Loss: 0.5227\n",
      "  Validation Loss: 0.5944\n",
      "  Validation Accuracy: 0.7049\n",
      "  Validation F1 Score: 0.4418\n",
      "  Validation AUC: 0.6584\n",
      "Epoch 5/10:\n",
      "  Training Loss: 0.4713\n",
      "  Validation Loss: 0.6237\n",
      "  Validation Accuracy: 0.6645\n",
      "  Validation F1 Score: 0.4803\n",
      "  Validation AUC: 0.6473\n",
      "Epoch 6/10:\n",
      "  Training Loss: 0.3725\n",
      "  Validation Loss: 0.6456\n",
      "  Validation Accuracy: 0.6539\n",
      "  Validation F1 Score: 0.4759\n",
      "  Validation AUC: 0.6712\n",
      "Early stopping triggered. Stopping training.\n",
      "CPU times: user 23min 59s, sys: 41.9 s, total: 24min 41s\n",
      "Wall time: 17min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#2700\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "model_vgg16.classifier[6] = torch.nn.Linear(model_vgg16.classifier[6].in_features, 1)\n",
    "model_vgg16 = model_vgg16.to(device)\n",
    "\n",
    "train(model_vgg16,train_loader,val_loader,1e-5,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f0885-5fd3-43e0-b4a9-6fa98aff452c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
